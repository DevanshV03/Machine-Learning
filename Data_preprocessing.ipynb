{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGcs3LdEg5nSr0+ESZEgUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevanshV03/Machine-Learning/blob/main/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Libraries\n"
      ],
      "metadata": {
        "id": "Rbli_293Jf3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RueLRSapJjMa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset\n"
      ],
      "metadata": {
        "id": "4corYkejJt7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"Data.csv\") #Creating the dataframe of the csv dataset and storing it in a variable named dataset\n",
        "#Creating the independent variable matrix \"X\"\n",
        "X = dataset.iloc[:, :-1].values #The iloc function selects all the rows between ranges [:], and takes all the columns except the upper bound {last column in this case}, .values is used to extract the values of the dataset from all those selected columns.\n",
        "#Creating a matrix of all the dependent variables\n",
        "Y = dataset.iloc[:, -1].values\n",
        "\n",
        "print(X)\n",
        "print(\"-------------------------------------------------\")\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aepRf9I3JwgT",
        "outputId": "3bcb2867-baef-4676-f1e1-df2c6ac0352e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "-------------------------------------------------\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking Care of missing data"
      ],
      "metadata": {
        "id": "UoyAJHdBWh49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing simpleimputer to handle missing values form sklearn\n",
        "from sklearn.impute import SimpleImputer\n",
        "#creating an object of the class SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\") #the missing values are defined as nan and will be replaced using the strategy mean\n",
        "#using the fit method to fit the impute object to the matrix of features(X)\n",
        "imputer.fit(X[:, 1:3]) #upper bound is ignored hence the range 1 to 3 is used\n",
        "#using the transform method to replace the missing values with the mean values\n",
        "X[:,1:3]= imputer.transform(X[:, 1:3])\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tquOaeR1Wkyo",
        "outputId": "994acd4f-4135-4f2f-db8e-6d958d13ef84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding categorical data\n"
      ],
      "metadata": {
        "id": "1sm47iEZXmrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding categorical data in the independent variables using compose class of skalearn from which ColumnTransformer is used\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder #Using the OneHotEncoder class to encode categorical data consisiting of several classes of categories\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder=\"passthrough\") #ColumnTransformer class takes two inputs Transformers and remainder, Transformers takes argument as what to do that is encode, what type of encoding to do that is OneHotEncoding and the columns on which the encoding is to be done, the second input it takes is the remainder which decides what to do with the columns in which encoding is not applied, here in this case it is passthrough that is to keep them as is in the output and not transform them\n",
        "X_transformed = ct.fit_transform(X)  #using the fit_transform method to apply the output of the column transformer to the new matrix of features, the np.array is used as column transformer does not give the output in the form of array and the machine learning model requires the input in the form of array.\n",
        "X = np.array(X_transformed)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U0BPGZfXrDG",
        "outputId": "857c2c81-929e-4248-da7d-3baf6b91b949"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the dependent variable using the class LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder() #Label encoder is used when the categorical data consists only 2 unique types of values\n",
        "Y = le.fit_transform(Y)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ51oDqQn5_5",
        "outputId": "86803334-edca-4f49-84be-7d781b7b6a8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training and test set"
      ],
      "metadata": {
        "id": "NQzPVRYt3Uww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y , test_size= 0.2, random_state= 1) #the random factor/state determines the randomness of the selection of the test and train sets if it is set to none it gives a different set of training and test set each time it is run, this is used when the stabiblity of the model is to be tested"
      ],
      "metadata": {
        "id": "w6wsrTib3bdD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIm2bN0p3x3q",
        "outputId": "ba3e1b11-314c-4840-94d3-30a8df5d5e83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRikzqeW3xux",
        "outputId": "933ba997-8c25-42d3-904e-e69137293615"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha57UwTg3xmu",
        "outputId": "44ff7f17-abbe-464a-9e83-a6c84341ff01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJfr3Epm3xeH",
        "outputId": "eff2dd07-ca0b-40be-8e74-f0c215b9fad9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying feature scaling on the dependent variables"
      ],
      "metadata": {
        "id": "WIi00RGdAfAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler #the standardscaler library applies standardization\n",
        "sc = StandardScaler()\n",
        "X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n",
        "X_test[:,3:] = sc.transform(X_test[:,3:]) #we only apply transform method so as to avoid creating a new scale of standardization based on the test set, we use only transform to apply the scale created using the training set"
      ],
      "metadata": {
        "id": "NY_CH2FVAlD3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WyU9qaABXNH",
        "outputId": "babdfe90-2017-4719-9047-9f98120cfd84"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJFQlJPBXE-",
        "outputId": "f2465337-1062-42b9-f5f8-632c41b2adda"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    }
  ]
}